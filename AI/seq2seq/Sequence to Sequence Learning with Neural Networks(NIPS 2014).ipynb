{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DZeY69nKuES"
   },
   "source": [
    "# Sequence to Sequence Learning with Neural Networks(NIPS 2014)\n",
    "- RNN LSTM, Attention 등을 공부하는 과정에서 seq2seq 모델을 공부하게 되었다.\n",
    "- seq2seq 모델은 전통적인 RNN 또는 LSTM 기반의 언어 모델과 달리, 인코더와 디코더를 사용하여 문장을 번역한다.\n",
    "- 전통적인 언어 모델은 다음과 같은 대표적인 한계점이 존재한다.\n",
    "    - 입력과 출력의 크기가 같다고 가정한다.\n",
    "    - 또한, 예를 들어 한글과 영어의 경우 어순이 완전히 다르기 때문에 번역 시 문장 간의 관계를 찾는데 어려움이 따른다.\n",
    "- seq2seq 모델은 인코더에서 고정된 크기의 context vector를 출력하고, context vector로부터 디코더가 번역한 결과를 추론하기\n",
    "때문에 위와 같은 한계점을 극복할 수 있다.\n",
    "- 이러한 seq2seq 모델을 아래의 링크를 참조하여 구현해보았다.  \n",
    "  [papar: Sequence to Sequence Learning with Neural Networks(NIPS, 2014)](https://arxiv.org/abs/1409.3215)  \n",
    "  [seq2seq review](https://www.youtube.com/watch?v=4DzKM0vgG1Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T13:28:13.389548Z",
     "start_time": "2021-04-07T13:28:13.377549Z"
    },
    "id": "yl4QjdC7NdDx"
   },
   "source": [
    "## 데이터 전처리(Prepocessing)\n",
    "- spaCy 라이브러리:\n",
    "    - 자연어 처리에서 많이 사용되는 파이썬 라이브러리\n",
    "    - 문장의 토큰화(tokenization), 태깅(tagging) 등의 전처리 기능을 위한 라이브러리\n",
    "    - 해당 라이브러리에서 영어(English)와 독일어(Deutsch) 전처리 모듈을 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:26.864404Z",
     "start_time": "2021-04-11T05:11:26.857403Z"
    },
    "id": "ZyngT7ezKuEY"
   },
   "outputs": [],
   "source": [
    "## Anaconda 프롬프트 상에서 실행함.\n",
    "# %%capture\n",
    "# !python -m spacy download en\n",
    "# !python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:29.325505Z",
     "start_time": "2021-04-11T05:11:26.865404Z"
    },
    "id": "5tQlxuTyKuEZ"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_en = spacy.load('en') # 영어 토큰화\n",
    "spacy_de = spacy.load('de') # 독일어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:29.340505Z",
     "start_time": "2021-04-11T05:11:29.326536Z"
    },
    "id": "1rh3RQrxKuEZ",
    "outputId": "37c589a3-03a4-4a58-e580-5743c5cc1c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0: I\n",
      "index 1: am\n",
      "index 2: a\n",
      "index 3: graduate\n",
      "index 4: student\n",
      "index 5: .\n"
     ]
    }
   ],
   "source": [
    "# 간단히 토큰화 기능 써보기\n",
    "tokenized = spacy_en.tokenizer(\"I am a graduate student.\")\n",
    "\n",
    "for i, token in enumerate(tokenized):\n",
    "    print(f\"index {i}: {token.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c16m7gbtKuEa"
   },
   "source": [
    "- 영어 및 독일어 토큰화 함수 정의\n",
    "    - 논문 상에서 입력에 사용하는 문장의 경우 문장의 뒤쪽부터 입력하는 것이 성능 향상에 매우 좋았다고 하였으므로, \n",
    "    입력으로 사용할 독일어의 경우 문장의 순서를 뒤집도록 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:29.355564Z",
     "start_time": "2021-04-11T05:11:29.341505Z"
    },
    "id": "k2xK40Y5KuEa"
   },
   "outputs": [],
   "source": [
    "# 독일어 문장을 토큰화한 뒤에 순서를 뒤집는 함수\n",
    "def de_tokenizer(text):\n",
    "    return [token.text for token in spacy_de.tokenizer(text)][::-1]\n",
    "# 영어 문장을 토큰화 하는 함수\n",
    "def en_tokenizer(text):\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T06:19:15.605456Z",
     "start_time": "2021-04-08T06:19:15.597441Z"
    },
    "id": "Z1Qn3DhfKuEa"
   },
   "source": [
    "- 필드(Field) 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시한다.\n",
    "- 번역 목표:\n",
    "    - 소스(SRC): 독일어\n",
    "    - 목표(TRG): 영어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:30.118577Z",
     "start_time": "2021-04-11T05:11:29.356535Z"
    },
    "id": "kAyVD9jwKuEb",
    "outputId": "65d25d63-777e-4558-d355-2d62571a2c99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torch1.6\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "SRC = Field(tokenize=de_tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)\n",
    "TRG = Field(tokenize=en_tokenizer, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZO0RxuIKuEb"
   },
   "source": [
    "- 대표적인 영어-독일어 번역 데이터셋인 __Multi30k__를 불러온다.\n",
    "- 일반적으로 언어 번역 관련 논문에서는 수백만 개의 문장으로 데이터셋을 사용하지만, 실습에서는 이보다는 적은 수인 3만개의 문장을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:33.907073Z",
     "start_time": "2021-04-11T05:11:30.119578Z"
    },
    "id": "zfN8HfTbKuEb",
    "outputId": "8c12e9e5-7a2e-4fe4-dbd3-2a8ed138f7ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torch1.6\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = Multi30k.splits(exts=(\".de\", \".en\"), fields=(SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:33.922981Z",
     "start_time": "2021-04-11T05:11:33.907985Z"
    },
    "id": "g8PbIRZiKuEc",
    "outputId": "1a977c3d-7f5d-4772-b77f-ec906346084d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 29000\n",
      "valid_dataset size: 1014\n",
      "test_dataset size: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_dataset size: {len(train_dataset.examples)}\")\n",
    "print(f\"valid_dataset size: {len(valid_dataset.examples)}\")\n",
    "print(f\"test_dataset size: {len(test_dataset.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:15:25.139029Z",
     "start_time": "2021-04-11T05:15:25.134032Z"
    },
    "id": "dkTvCKEAKuEc",
    "outputId": "d51d6fa0-f749-4aab-b85f-7042e213ab6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'gugelhupf', 'einem', 'auf', 'puderzucker', 'streut', 'brille', 'und', 'oberteil', 'schwarzem', 'mit', 'frau', 'eine']\n",
      "['a', 'lady', 'in', 'a', 'black', 'top', 'with', 'glasses', 'is', 'sprinkling', 'powdered', 'sugar', 'on', 'a', 'bundt', 'cake', '.']\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 중 하나를 선택해 출력\n",
    "print(vars(train_dataset.examples[15])['src']) # 출력 결과를 보면, 입력의 순서가 뒤바뀌어 마침표가 가장 앞에 오는 것을 알\n",
    "                                               # 수 있다.\n",
    "print(vars(train_dataset.examples[15])['trg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T06:53:07.214806Z",
     "start_time": "2021-04-08T06:53:07.195829Z"
    },
    "id": "Rl4nXr5DKuEc"
   },
   "source": [
    "- Field 객체의 build_vocab 메서드를 이용해 영어와 독일어의 단어 사전을 생성한다.\n",
    "- 이 때 min_freq 옵션을 사용해 최소 2번 이상 등장한 단어만 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:34.089989Z",
     "start_time": "2021-04-11T05:11:33.939982Z"
    },
    "id": "ht89Tc4oKuEd",
    "outputId": "fd6cbb4a-24a5-4407-df4e-f8a97aa3edda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of SRC: 7854\n",
      "len of TRG: 5893\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_dataset, min_freq=2)\n",
    "TRG.build_vocab(train_dataset, min_freq=2)\n",
    "\n",
    "print(f\"len of SRC: {len(SRC.vocab)}\")\n",
    "print(f\"len of TRG: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:23:52.353232Z",
     "start_time": "2021-04-08T07:23:52.349238Z"
    },
    "id": "siAnLK7yKuEd"
   },
   "source": [
    "- 위의 코드를 통해 단어 사전이 생성되면 SRC.vocab.stoi는 어휘에 해당하는 토큰을 키로, \n",
    "관련된 색인을 값으로 가지는 dictionary가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:34.104989Z",
     "start_time": "2021-04-11T05:11:34.090983Z"
    },
    "id": "t5ISpXofKuEd",
    "outputId": "8e73204e-f3fb-444c-97f4-fce1506d4322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4112\n",
      "1752\n"
     ]
    }
   ],
   "source": [
    "print(TRG.vocab.stoi['abcabc']) # 없는 단어: 0\n",
    "print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding): 1\n",
    "print(TRG.vocab.stoi[\"<sos>\"]) # <sos>: 2\n",
    "print(TRG.vocab.stoi[\"<eos>\"]) # <eos>: 3\n",
    "print(TRG.vocab.stoi[\"hello\"])\n",
    "print(TRG.vocab.stoi[\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10keVx9FKuEd"
   },
   "source": [
    "- 한 문장에 포함된 단어가 연속적으로 LSTM에 입력되어야 한다.\n",
    "- 또한, 하나의 배치에 포함된 문장들이 가지는 단어의 개수가 유사할 때 효율적으로 학습시킬 수 있다.\n",
    "- 이를 위해 BucketIterator를 사용하는데, BucketIterator는 배치 크기(batch_size)에 따라 각각의 배치가 길이가 비슷한 문장으로\n",
    "구성되도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:34.119990Z",
     "start_time": "2021-04-11T05:11:34.105982Z"
    },
    "id": "LutzF2P3KuEe",
    "outputId": "3e8e22ac-1b07-49c5-c3fc-d59192e08f48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torch1.6\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 일반적인 data_loader의 iterator와 유사하게 사용 가능\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_dataset, valid_dataset, test_dataset),\n",
    "                                                                     batch_size=BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCGY3SoYKuEe"
   },
   "source": [
    "- 아래는 첫 번째 배치의 첫번째 문장 정보를 출력하는 코드이다.\n",
    "- 첫번째 배치의 길이는 28이므로, 첫번째 배치의 모든 문장의 길이가 28이 되도록 패딩된 것을 알 수 있다.\n",
    "- 문장의 길이에 따라 패딩이 들어가므로, 아래에서 1로 된 값들은 패딩되어 추가된 부분을 의미한다.\n",
    "- 또한 index 0에는 2, index 16에는 3이 입력되어 있는 것을 볼 수 있는데, 이는 각각 \"<sos>\", \"<eos>\"에 해당하는 단어 사전의 색인값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:11:34.166003Z",
     "start_time": "2021-04-11T05:11:34.120983Z"
    },
    "id": "N9y1XTJYKuEe",
    "outputId": "819fed63-010b-412d-ceee-440fa463f623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of first batch: torch.Size([28, 128])\n",
      "index 0: 2\n",
      "index 1: 4\n",
      "index 2: 1850\n",
      "index 3: 281\n",
      "index 4: 10\n",
      "index 5: 2672\n",
      "index 6: 6\n",
      "index 7: 12\n",
      "index 8: 505\n",
      "index 9: 100\n",
      "index 10: 207\n",
      "index 11: 24\n",
      "index 12: 11\n",
      "index 13: 156\n",
      "index 14: 13\n",
      "index 15: 5\n",
      "index 16: 3\n",
      "index 17: 1\n",
      "index 18: 1\n",
      "index 19: 1\n",
      "index 20: 1\n",
      "index 21: 1\n",
      "index 22: 1\n",
      "index 23: 1\n",
      "index 24: 1\n",
      "index 25: 1\n",
      "index 26: 1\n",
      "index 27: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torch1.6\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    # 각 배치는 src 및 trg 속성을 가진다.\n",
    "    src = batch.src\n",
    "    trg = batch.trg\n",
    "    \n",
    "    print(f\"Shape of first batch: {src.shape}\")\n",
    "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
    "    for i in range(src.shape[0]):\n",
    "        print(f\"index {i}: {src[i][0].item()}\")\n",
    "    # 첫번째 배치만 확인    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI09pm4aKuEe"
   },
   "source": [
    "## 인코더(Encoder) 아키텍쳐\n",
    "- 인코더는 주어진 소스 문장을 context vector로 인코딩한다.\n",
    "- 인코더와 디코더는 디코더에는 FC층이 추가된 다는 것 빼고는 거의 유사한 구조를 가진다.\n",
    "- LSTM은 hidden state와 cell state를 리턴한다.\n",
    "- 하이퍼 파라미터는 아래와 같다.\n",
    "    - __input_dim__: 하나의 단어에 대한 원핫 인코딩 차원\n",
    "    - __embed_dim__: 임베딩(embedding) 차원\n",
    "    - __hidden_dim__: 히든 상태(hidden state) 차원\n",
    "    - __n_layers__: LSTM 층 개수\n",
    "        - 기존 논문에서는 LSTM을 4번 중첩하여 사용하였지만, 이번 실습에서는 LSTM을 2번 중첩하여 사용한다.\n",
    "    - __dropout_ratio__: 드롭아웃 비율(일반적으로 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:39:29.659851Z",
     "start_time": "2021-04-11T05:39:29.649855Z"
    },
    "id": "JrV1Euv5KuEf"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 인코더 아키텍쳐 정의\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers, dropout_ratio):\n",
    "        super().__init__()\n",
    "        # 임베딩(embedding)은 원-핫 인코딩을 특정 차원의 임베딩으로 매핑하는 층\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        # LSTM 층\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout_ratio)\n",
    "        # 드롭아웃(dropout)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        \n",
    "    # 인코더는 소스 문장을 입력으로 받아 context vector를 반환\n",
    "    def forward(self, src):\n",
    "        # src: [단어 개수, 배치 크기]: 각 단어의 단어 사전 인덱스(index) 정보\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded: [단어 개수, 배치 크기, 임베딩 차원]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # output: [단어 개수, 배치 크기, 히든 차원] -> 현재 단어의 출력 정보 \n",
    "        # 인코더에서는 output은 사용되지 않고, 문맥 정보를 담은 hidden과 cell만 사용한다.\n",
    "        # hidden: [층 개수, 배치 크기, 히든 차원] -> 현재까지의 모든 단어의 단기 기억 정보\n",
    "        # cell: [층 개수, 배치 크기, 히든 차원] -> 현재까지의 모든 단어의 장기 기억 정보\n",
    "        \n",
    "        # context vector 반환\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T05:43:30.297568Z",
     "start_time": "2021-04-11T05:43:30.285571Z"
    },
    "id": "jCItadXWKuEf"
   },
   "source": [
    "## 디코더(Decoder) 아키텍쳐\n",
    "- 인코더와 아키텍쳐는 유사하다.\n",
    "- 주어진 context vector를 타겟 문장으로 디코딩한다.\n",
    "- LSTM은 hidden state와 cell state를 반환한다.\n",
    "- 하이퍼 파라미터는 아래와 같다.\n",
    "    - __output_dim__: 하나의 단어에 대한 원핫 인코딩 차원\n",
    "    - __embed_dim__: 임베딩(embedding) 차원\n",
    "    - __hidden_dim__: 히든 상태(hidden state) 차원\n",
    "    - __n_layers__: LSTM 층 개수\n",
    "    - __dropout_ratio__: 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T06:44:39.173987Z",
     "start_time": "2021-04-11T06:44:39.153987Z"
    },
    "id": "hl_IvabGKuEf"
   },
   "outputs": [],
   "source": [
    "# 디코더 아키텍쳐 정의\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emded_dim, hidden_dim, n_layers, dropout_ratio):\n",
    "        super().__init__()\n",
    "        # 임베딩은 원-핫 인코딩 말고 특정 차원의 임베딩으로 매핑하는 층\n",
    "        self.embedding = nn.Embedding(output_dim, emded_dim)\n",
    "        # LSTM 층\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.LSTM(emded_dim, hidden_dim, n_layers, dropout=dropout_ratio)\n",
    "        # FC 층(인코더와 구조적으로 다른 부분)\n",
    "        self.output_dim = output_dim\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        # 드롭아웃(dropout)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "    # forward 함수는 단어를 하나씩 입력하고, \n",
    "    # 출력 단어, 현재까지의 모든 단어의 장/단기 기억 정보를 리턴한다.\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input: [배치 크기] -> 단어의 개수는 항상 1개 이도록 구현\n",
    "        # hidden: [층 개수, 배치 크기, 히든 차원]\n",
    "        # cell = context: [층 개수, 배치 크기, 히든 차원]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input: [단어 개수 = 1, 배치 크기]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded: [단어 개수, 배치 크기, 임베딩 차원]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output: [단어 개수 = 1, 배치 크기, 히든 차원] -> 현재 단어의 출력 정보\n",
    "        # hidden: [층 개수, 배치 크기, 히든 차원] -> 현재까지의 모든 단어의 단기 기억 정보\n",
    "        # cell: [층 개수, 배치 크기, 히든 차원] -> 현재까지의 모든 단어의 장기 기억 정보\n",
    "        \n",
    "        # 단어 개수는 어차피 1개이므로 차원 제거\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction: [배치 크기, 출력 차원]\n",
    "        \n",
    "        # (현재 출력 단어, 현재까지의 모든 단어의 단기 기억 정보, 현재까지의 모든 단어의 장기 기억 정보)를 리턴한다.\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T06:03:09.874010Z",
     "start_time": "2021-04-11T06:03:09.858036Z"
    },
    "id": "HdFj2F82KuEg"
   },
   "source": [
    "## Seq2seq 아키텍쳐\n",
    "- 앞서 정의한 인코더와 디코더를 가지고 있는 하나의 아키텍쳐이다.\n",
    "    - 인코더: 주어진 소스 문장을 context vector로 인코딩한다.\n",
    "    - 디코더: 주어진 context vector를 타겟 문장으로 디코딩한다.\n",
    "    - 디코더는 한 단어씩 입력하여 한 번씩 결과를 출력한다.\n",
    "- Teacher Forcing 기법: 디코더의 예측(prediction)을 다음 입력으로 사용하지 않고, 실제 타겟 출력(ground-truth)을 \n",
    "    다음 입력으로 사용하는 기법이다.\n",
    "    - 이 방법을 사용할 때 훨씬 좋은 성능이 나온다고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T06:44:55.407343Z",
     "start_time": "2021-04-11T06:44:55.400343Z"
    },
    "id": "JdzwLZC7KuEg"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    # 학습할 때는 완전한 형태의 소스 문장, 타켓 문장, teacher_forcing_ratio를 입력한다.\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: [단어 개수, 배치 크기]\n",
    "        # trg: [단어 개수, 배치 크기]\n",
    "        \n",
    "        # 먼저 인코더를 거쳐 context vector를 도출\n",
    "        hidden, cell = self.encoder(src)\n",
    "        # 디코더의 최종 결과를 담을 텐서 객체 생성\n",
    "        trg_len = trg.shape[0] # 단어 개수\n",
    "        batch_size = trg.shape[1] # 배치 크기\n",
    "        trg_vocab_size = self.decoder.output_dim # 출력 차원\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # 첫 번째 입력은 항상 \"<sos>\" 토큰\n",
    "        input = trg[0, :] # 배치 내 각 문장의 첫번째 단어(\"<sos>\")를 입력\n",
    "        \n",
    "        # 타겟 단어의 개수만큼 반복하여 디코더에 포워딩(forwarding)\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            outputs[t] = output     # FC를 거쳐서 나온 현재의 출력 단어 정보\n",
    "            top1 = output.argmax(1) # 배치 단위로 각 단어에서 가장 확률이 높은 단어의 인덱스 추출\n",
    "                                    # output([배치 크기, 출력 차원])은 각 단어의 원-핫 인코딩 형태\n",
    "            \n",
    "            # teacher_forcing_ratio: 학습 시 실제 목표 출력(ground truth)을 사용하는 비율\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = trg[t] if teacher_force else top1 # 현재의 출력 결과를 다음 입력에 삽입\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pp_YG1v_KuEg"
   },
   "source": [
    "## 학습(Training)\n",
    "- 하이퍼 파라미터 설정 및 모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T06:41:28.356538Z",
     "start_time": "2021-04-11T06:41:28.346541Z"
    },
    "id": "7yjtdlFhKuEh"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENCODER_EMBED_DIM = 256\n",
    "DECODER_EMBED_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT_RATIO = 0.5\n",
    "DEC_DROPOUT_RATIO = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T06:44:59.310413Z",
     "start_time": "2021-04-11T06:44:59.235411Z"
    },
    "id": "edTYkppdKuEh"
   },
   "outputs": [],
   "source": [
    "# 인코더와 디코더 객체 선언\n",
    "enc = Encoder(INPUT_DIM, ENCODER_EMBED_DIM, HIDDEN_DIM, N_LAYERS, ENC_DROPOUT_RATIO)\n",
    "dec = Decoder(OUTPUT_DIM, DECODER_EMBED_DIM, HIDDEN_DIM, N_LAYERS, DEC_DROPOUT_RATIO)\n",
    "\n",
    "# seq2seq 객체 선언\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWq5jSHzKuEh"
   },
   "source": [
    "- 논문의 내용대로 $\\mu$(-0.08, 0.08)의 값으로 모델의 가중치 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T06:47:27.092497Z",
     "start_time": "2021-04-11T06:47:26.900499Z"
    },
    "id": "AZQvOf2pKuEh",
    "outputId": "5b6c74d8-5761-4153-a6db-3cefdc90a5a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7854, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ScLt1sRKuEi"
   },
   "source": [
    "- 학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T06:55:16.328276Z",
     "start_time": "2021-04-11T06:55:16.319278Z"
    },
    "id": "d-V6KLmFKuEi"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Adam optimizer로 학습 최적화\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 손실값을 계산할 때 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
    "# 애초에 단어가 존재하지 않기 때문에 패딩을 해당 위치에 채워넣은 것이기 때문\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T07:29:07.746958Z",
     "start_time": "2021-04-11T07:29:07.739958Z"
    },
    "id": "-zS7fyJQKuEi"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 모델 학습 함수 정의\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train() # 학습 모드\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # 전체 학습 데이터를 확인하며\n",
    "    for batch in tqdm(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        # output: [출력 단어 개수, 배치 크기, 출력 차원]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        # 출력 단어의 인덱스 0은 사용하지 않음\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(출력 단어 개수 - 1) * 배치 크기, output_dim]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(타겟 단어 개수 - 1) * 배치 크기]\n",
    "        \n",
    "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward() # 그레디언트 계산\n",
    "        \n",
    "        # 그레디언트 clipping 진행(논문 내용)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        # 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 전체 손실 값 계산\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T07:48:29.197944Z",
     "start_time": "2021-04-11T07:48:29.185944Z"
    },
    "id": "qItySc08KuEi"
   },
   "outputs": [],
   "source": [
    "# 모델 평가 함수 정의\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval() # 평가 모드\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 전체 평가 데이터를 확인하며\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            \n",
    "            # 평가할 때 teacher forcing은 사용하지 않음\n",
    "            output = model(src, trg, 0)\n",
    "            # output: [출력 단어 개수, 배치 크기, 출력 차원]\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            # 출력 단어의 인덱스 0은 사용하지 않음\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output: [(출력 단어 개수 - 1) * 배치 크기, 출력 차원]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg: [(타겟 단어의 개수 - 1) * 배치 크기]\n",
    "            \n",
    "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            # 전체 손실 값 계산\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK9IPz47KuEi"
   },
   "source": [
    "- 학습 및 검증 진행\n",
    "    - 학습 횟수(epoch): 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T07:16:50.347089Z",
     "start_time": "2021-04-11T07:16:50.329120Z"
    },
    "id": "TQ9LDTdkKuEj"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T11:13:31.347307Z",
     "start_time": "2021-04-11T07:48:36.296314Z"
    },
    "id": "3RAl67KtKuEj",
    "outputId": "6c74e182-2c1f-4fed-a51e-f2ac9bec4f3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]D:\\Anaconda\\envs\\torch1.6\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:30<00:00,  2.78s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 10m 33s\n",
      "\tTrain loss: 4.396 | Train PPL: 81.162\n",
      "\tValidation loss: 4.703 | Validation PPL: 110.330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:25<00:00,  2.76s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 10m 28s\n",
      "\tTrain loss: 4.116 | Train PPL: 61.297\n",
      "\tValidation loss: 4.547 | Validation PPL: 94.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:25<00:00,  2.76s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 10m 28s\n",
      "\tTrain loss: 3.951 | Train PPL: 51.970\n",
      "\tValidation loss: 4.379 | Validation PPL: 79.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:17<00:00,  2.72s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 10m 20s\n",
      "\tTrain loss: 3.785 | Train PPL: 44.028\n",
      "\tValidation loss: 4.315 | Validation PPL: 74.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:20<00:00,  2.73s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 10m 23s\n",
      "\tTrain loss: 3.621 | Train PPL: 37.388\n",
      "\tValidation loss: 4.196 | Validation PPL: 66.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:29<00:00,  2.77s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 10m 32s\n",
      "\tTrain loss: 3.519 | Train PPL: 33.746\n",
      "\tValidation loss: 4.138 | Validation PPL: 62.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:20<00:00,  2.73s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 10m 23s\n",
      "\tTrain loss: 3.361 | Train PPL: 28.828\n",
      "\tValidation loss: 4.122 | Validation PPL: 61.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:22<00:00,  2.74s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 10m 25s\n",
      "\tTrain loss: 3.247 | Train PPL: 25.709\n",
      "\tValidation loss: 3.983 | Validation PPL: 53.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:20<00:00,  2.73s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 10m 23s\n",
      "\tTrain loss: 3.124 | Train PPL: 22.729\n",
      "\tValidation loss: 3.936 | Validation PPL: 51.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:22<00:00,  2.74s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 10m 25s\n",
      "\tTrain loss: 3.022 | Train PPL: 20.536\n",
      "\tValidation loss: 3.890 | Validation PPL: 48.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [09:51<00:00,  2.60s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 9m 54s\n",
      "\tTrain loss: 2.930 | Train PPL: 18.735\n",
      "\tValidation loss: 3.861 | Validation PPL: 47.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:09<00:00,  2.69s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 10m 13s\n",
      "\tTrain loss: 2.829 | Train PPL: 16.927\n",
      "\tValidation loss: 3.795 | Validation PPL: 44.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:08<00:00,  2.68s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 10m 11s\n",
      "\tTrain loss: 2.751 | Train PPL: 15.653\n",
      "\tValidation loss: 3.777 | Validation PPL: 43.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [09:58<00:00,  2.64s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 10m 1s\n",
      "\tTrain loss: 2.656 | Train PPL: 14.234\n",
      "\tValidation loss: 3.771 | Validation PPL: 43.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:10<00:00,  2.69s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 10m 13s\n",
      "\tTrain loss: 2.596 | Train PPL: 13.410\n",
      "\tValidation loss: 3.756 | Validation PPL: 42.770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:12<00:00,  2.70s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 10m 15s\n",
      "\tTrain loss: 2.539 | Train PPL: 12.667\n",
      "\tValidation loss: 3.684 | Validation PPL: 39.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [10:09<00:00,  2.69s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 10m 12s\n",
      "\tTrain loss: 2.432 | Train PPL: 11.383\n",
      "\tValidation loss: 3.766 | Validation PPL: 43.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [09:45<00:00,  2.58s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 9m 48s\n",
      "\tTrain loss: 2.404 | Train PPL: 11.065\n",
      "\tValidation loss: 3.727 | Validation PPL: 41.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [09:42<00:00,  2.56s/it]\n",
      "  0%|                                                                                          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 9m 45s\n",
      "\tTrain loss: 2.300 | Train PPL: 9.976\n",
      "\tValidation loss: 3.731 | Validation PPL: 41.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227/227 [09:48<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 9m 51s\n",
      "\tTrain loss: 2.268 | Train PPL: 9.656\n",
      "\tValidation loss: 3.713 | Validation PPL: 40.971\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time() # 시작 시간 기록\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time() # 종료 시간 기록\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'seq2seq.pt')\n",
    "        \n",
    "    print(f\"Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}\")\n",
    "    print(f\"\\tValidation loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T12:40:33.800421Z",
     "start_time": "2021-04-11T12:40:30.624421Z"
    },
    "id": "12BoDOJbKuEj",
    "outputId": "4379b905-0f32-4c3f-80c2-8f10d3d50934"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torch1.6\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.698 | Test PPL: 40.375\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('seq2seq.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f\"Test loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2E5aY_XJKuEj"
   },
   "source": [
    "## 나만의 데이터로 모델 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T12:40:52.381245Z",
     "start_time": "2021-04-11T12:40:52.373247Z"
    },
    "id": "MDcNuY19KuEj"
   },
   "outputs": [],
   "source": [
    "# 번역(translate) 함수\n",
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
    "    model.eval() # 평가 모드\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    \n",
    "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    print(f\"전체 소스 토큰: {tokens}\")\n",
    "    \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    print(f\"소스 문장 인덱스: {src_indexes}\")\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    \n",
    "    # 인코더에 소스 문장을 넣어 context vector 계산\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "    \n",
    "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        # 이전에 출력한 단어가 현재 단어로 입력될 수 있도록 \n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "        \n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
    "        \n",
    "        # <eos>를 만나는 순간 끝\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "        \n",
    "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
    "    trg_tokens = [trg_field.vocab.itos[vocab_idx] for vocab_idx in trg_indexes]\n",
    "    \n",
    "    # 첫번째 <sos>는 제외하고 출력 문장 반환\n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa4OfcQTKuEk"
   },
   "source": [
    "- 출력 결과를 보면, 소스 문장을 입력하였을 때 타겟 문장과 완전히 똑같지는 않지만, 비슷한 결과를 내는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T12:40:55.731151Z",
     "start_time": "2021-04-11T12:40:55.675154Z"
    },
    "id": "mno7qls6KuEk",
    "outputId": "ee7914c4-5f4e-40b3-f266-cc86d6b57d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 문장: ['.', 'freien', 'im', 'tag', 'schönen', 'einen', 'genießen', 'sohn', 'kleiner', 'ihr', 'und', 'mutter', 'eine']\n",
      "타겟 문장: ['a', 'mother', 'and', 'her', 'young', 'song', 'enjoying', 'a', 'beautiful', 'day', 'outside', '.']\n",
      "전체 소스 토큰: ['<sos>', '.', 'freien', 'im', 'tag', 'schönen', 'einen', 'genießen', 'sohn', 'kleiner', 'ihr', 'und', 'mutter', 'eine', '<eos>']\n",
      "소스 문장 인덱스: [2, 4, 88, 20, 200, 780, 19, 565, 624, 70, 134, 10, 364, 8, 3]\n",
      "모델 출력 결과: a mother and her son are in in a public park . <eos>\n"
     ]
    }
   ],
   "source": [
    "example_idx = 10\n",
    "\n",
    "src = vars(test_dataset.examples[example_idx])['src']\n",
    "trg = vars(test_dataset.examples[example_idx])['trg']\n",
    "\n",
    "print(f'소스 문장: {src}')\n",
    "print(f'타겟 문장: {trg}')\n",
    "print('모델 출력 결과:', \" \".join(translate_sentence(src, SRC, TRG, model, device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rWQ1mRCKuEk"
   },
   "source": [
    "- 새로운 입력을 입력하였을 때에는 제대로된 결과를 내지는 못했지만, 실습을 참고한 코드에서는 정확한 결과를 낸 것을 확인하였다.\n",
    "- 데이터셋의 크기가 크지 않고 모델이 아직은 충분히 학습되지 못하여 이러한 결과를 낸 것으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T12:51:09.401883Z",
     "start_time": "2021-04-11T12:51:09.378883Z"
    },
    "id": "q-Rc7YQ9KuEk",
    "outputId": "f60f2824-19f2-4067-bd31-ac3e68d29c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 문장: ['.', 'abend', 'Guten']\n",
      "전체 소스 토큰: ['<sos>', '.', 'abend', 'guten', '<eos>']\n",
      "소스 문장 인덱스: [2, 4, 1163, 3798, 3]\n",
      "모델 출력 결과: <unk> . <eos>\n"
     ]
    }
   ],
   "source": [
    "src = de_tokenizer(\"Guten abend.\")\n",
    "\n",
    "print(f'소스 문장: {src}')\n",
    "print('모델 출력 결과:', \" \".join(translate_sentence(src, SRC, TRG, model, device)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sequence to Sequence Learning with Neural Networks(NIPS 2014).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
