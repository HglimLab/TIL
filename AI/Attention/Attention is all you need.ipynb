{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0b7dea5568a8011761eb94fc783bf0961f4238ecb1b6b3a02e938e0ea93593243",
   "display_name": "Python 3.7.9 64-bit ('tf2.0': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Attention is all you need(NIPS 2017)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- 어텐션: 쿼리 행렬과 키 행렬에 행렬곱을 수행한 후 소프트맥스를 취해서 value 행렬에 적용할 웨이트를 구하는 것이 행렬곱 어텐션의 기본 구조이다.\n",
    "\n",
    "- 쿼리 행렬과 키 행렬을 곱함으로써 둘 사이의 연관성을 파악하게 된다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- 이번에는 2021년 기준 현대의 자연어 처리 네트워크에서 가장 핵심이 되는 모델 중 하나인 `트랜스포머(Transformer)`에 대해 실습해보려고 한다. \n",
    "- 트랜스포머는 기존의 `seq2seq` 모델과 동일하게 인코더와 디코더 구조를 사용한다.\n",
    " 그러나 인코더와 디코더에서 RNN이나 CNN을 전혀 사용하지 않고, Attention 과정을 여러번 반복한다는 특징이 있다.\n",
    "- 이를 통해 연산 횟수를 기존의 `seq2seq` 모델보다 확연히 줄이고, 병렬 연산의 정도도 늘어나 학습 시간도 크게 단축할 수 있었다고 한다.\n",
    "이번에는 2021년 기준 현대의 자연어 처리 네트워크에서 가장 핵심이 되는 모델 중 하나인 `트랜스포머(Transformer)`에 대해 실습해보려고 한다.\n",
    "- 트랜스포머는 기존의 `seq2seq` 모델과 동일하게 인코더와 디코더 구조를 사용한다.\n",
    "- 그러나 인코더와 디코더에서 RNN이나 CNN을 전혀 사용하지 않고, Attention 과정을 여러번 반복한다는 특징이 있다.\n",
    "- 이를 통해 연산 횟수를 기존의 `seq2seq` 모델보다 확연히 줄이고, 병렬 연산의 정도도 늘어나 학습 시간도 크게 단축할 수 있었다고 한다.\n",
    "- 현재 자연어 처리에서 가장 최신 네크워크 중 하나인 `BERT`도 트랜스포머의 구조를 채택하고 있다.\n",
    "- 아래의 링크를 참조하여 트랜스포머를 구현해보았다.  \n",
    "[paper: Attention is all you need(NIPS 2017)](https://arxiv.org/pdf/1706.03762.pdf)  \n",
    "[Seq2Seq with attention + Transformer review](https://www.youtube.com/watch?v=AA621UofTUA)  \n",
    "[Tensorflow tutorial](https://www.tensorflow.org/tutorials/text/transformer)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- 트랜스포머의 가장 핵심 아이디어는 `self-attention`이다.\n",
    "- 문장 번역을 예로 들면, `self-attention`을 이용하여 입력 문장의 단어들이 서로에 대한 연관성을 파악하여 해당 문장의 표현(representation of that sequence)을 구할 수 있다.\n",
    "- 트랜스포머는 이러한 `self-attention` 층을 여러 층 쌓는 방식으로 모델을 생성하였다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- 트랜스포머는 RNN이나 CNN을 사용하지 않고도 self-attention을 여러 층 사용하는 방식으로 variable-sized input을 처리할 수 있는데, 이러한 아키텍쳐는 아래와 같은 이점이 있다.\n",
    "    - 데이터 전체에 걸쳐 시/공간적 관계를 가정하지 않는데 이는 a set of objects를 처리하는데 매우 적합하다.\n",
    "    - RNN의 경우 입력 sequence를 순차적으로 입력해야 하는데, 트랜스포머의 경우 이를 병렬적으로 한번에 입력할 수 있다.\n",
    "    - 멀리 떨어져 있는 값들(distant items)이 RNN이나 CNN의 통과 없이도 서로의 출력에 영향을 미칠 수 있다.\n",
    "    - 따라서 트랜스포머는 long-range dependencies를 학습할 수 있다.\n",
    "- 트랜스포머 아키텍쳐에는 이점만 있는 것이 아니라 다음과 같은 단점도 있다.\n",
    "    - time-series 데이터의 경우 RNN을 사용할 때에는 각각의 타임 스텝마다의 출력이 현재의 입력과 hidden-state에 의해 계산되었지만, 트랜스포머에서는 전체 기록(entire history)가 구해져야 계산될 수 있는데 이는 비효율적일 수 있다.\n",
    "    - 텍스트와 같이 데이터에 시/공간적 관계가 있는 경우 데이터에 이러한 관계를 넣어줄 수 있는 positional encoding을 추가하거나 bag of words를 사용하여야 한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup\n",
    "# $ pip install -q tensorflow_datasets\n",
    "# $ pip install -q tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as text\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "source": [
    "### 데이터셋 다운로드\n",
    "- tensorflow_datasets를 사용하여 `TED Talks Open Translation Project`의 포르투갈어-영어 번역 데이터셋을 다운로드한다.\n",
    "- 출력을 보면, train_set에는 51785개의 문장이, validation_set에는 1193개의 문장이 포함되어 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(51785, 1193)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "train_examples, val_examples = examples['train'], examples['validation']\n",
    "len(train_examples), len(val_examples)"
   ]
  },
  {
   "source": [
    "- tensorflow_datasets에 의해 리턴된 `tf.data.Dataset` 객체는 포트투갈어-영어의 텍스트 쌍을 생성한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\nmas e se estes fatores fossem ativos ?\nmas eles não tinham a curiosidade de me testar .\n\nand when you improve searchability , you actually take away the one advantage of print , which is serendipity .\nbut what if it were active ?\nbut they did n't test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "    for pt in pt_examples.numpy():\n",
    "        print(pt.decode('utf-8'))\n",
    "    print()\n",
    "    for en in en_examples.numpy():\n",
    "        print(en.decode('utf-8'))"
   ]
  },
  {
   "source": [
    "### 텍스트 tokenization & detokenization\n",
    "- 데이터셋의 문장들을 문자 형태 그대로 인공신경망을 학습시킬 수는 없으므로 이를 먼저 인공신경망이 이해할 수 있는 숫자 데이터(numeric representation)로 변환하여야 한다.\n",
    "- 일반적으로는 이를 위해 하나의 단어가 하나의 token ID를 가지도록 하여 각 문장을 sequences of token IDs로 변환한다.\n",
    "- 이 token ID는 임베딩을 할 때 단어에 대한 인덱스로 사용된다.\n",
    "- 문장을 tokenize하는 방법에는 `Subword tokenizer tutorial`의 내용에 따라 이번에 사용하는 데이터셋에 최적화된 subword tokenizers인 text.BertTokenizer를 빌드하고 이를 saved_model로 export하여 사용하는 방법이 있다.\n",
    "- 아래의 코드는 tokenizer를 다운로드하고 saved_model로 불러오는 코드이다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'.\\\\./ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "model_name = \"ted_hrlr_translate_pt_en_converter\"\n",
    "tf.keras.utils.get_file(\n",
    "    f\"{model_name}.zip\",\n",
    "    f\"https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ]
  },
  {
   "source": [
    "- tokenizers.en에는 아래와 같은 메서드를 포함하고 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['detokenize',\n",
       " 'get_reserved_tokens',\n",
       " 'get_vocab_path',\n",
       " 'get_vocab_size',\n",
       " 'lookup',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'vocab']"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
   ]
  },
  {
   "source": [
    "- 위에서 `tokenize` 메서드는 문장 배치를 토큰 ID로 이루어진 padded-batch로 변환해준다.\n",
    "- 또한 토큰화하기 전에 구두점(punctuation)을 분할하고 입력된 문장을 unicode로 normalize한다.\n",
    "- 이번 실습에서는 입력 문장이 이미 standardize되어 있으므로 이러한 standardization은 볼 수 없다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\nbut what if it were active ?\nbut they did n't test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": " Trying to access resource using the wrong type. Expected class tensorflow::lookup::LookupInterface got class tensorflow::lookup::LookupInterface\n\t [[{{node StatefulPartitionedCall/WordpieceTokenizeWithOffsets/WordpieceTokenizeWithOffsets/WordpieceTokenizeWithOffsets}}]] [Op:__inference_restored_function_body_6879]\n\nFunction call stack:\nrestored_function_body\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-bda9fa74a150>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[1;32m--> 895\u001b[1;33m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Trying to access resource using the wrong type. Expected class tensorflow::lookup::LookupInterface got class tensorflow::lookup::LookupInterface\n\t [[{{node StatefulPartitionedCall/WordpieceTokenizeWithOffsets/WordpieceTokenizeWithOffsets/WordpieceTokenizeWithOffsets}}]] [Op:__inference_restored_function_body_6879]\n\nFunction call stack:\nrestored_function_body\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)"
   ]
  }
 ]
}